{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnFreTh/STREAM/blob/main/docs/notebooks/datasets.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/AnFreTh/STREAM/blob/main/docs/notebooks/datasets.ipynb)\n",
    "\n",
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset module provides and easy way to load and preprocess the datasets. The package comes with a few datasets that are commonly used in topic modleing research. The datasets are:\n",
    "\n",
    "- 20NewsGroup\n",
    "- BBC_News\n",
    "- Stocktwits_GME\n",
    "- Reddit_GME'\n",
    "- Reuters'\n",
    "- Spotify\n",
    "- Spotify_most_popular\n",
    "- Poliblogs\n",
    "- Spotify_least_popular\n",
    "\n",
    "Please see the functionalities availabe in the `TMDataset` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Make sure the `nltk` dependencies are installed. If not, please run the following command:\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line if running in Colab\n",
    "# package neeeds to be installed for the notebook to run\n",
    "\n",
    "# ! pip install -U stream_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream_topic.utils import TMDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using default datasets\n",
    "\n",
    "- these datasets are already preprocessed and ready to be used for topic modeling\n",
    "- these datasets are included in the package and can be loaded using the `TMDataset` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 15:32:39.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFetching dataset: Reuters\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:40.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mDownloading dataset from github\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:40.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1mDataset downloaded successfully at ~/stream_topic_data/\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:40.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mDownloading dataset info from github\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:40.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mDataset info downloaded successfully at ~/stream_topic_data/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = TMDataset()\n",
    "dataset.fetch_dataset(name=\"Reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array(['00', '000', '001', ..., 'zurich', 'zverev', 'zzzz'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array(['00', '000', '001', ..., 'zurich', 'zverev', 'zzzz'], dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.get_word_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 15:32:42.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mDataset name already provided while instantiating the class: Reuters\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:42.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mOverwriting the dataset name with the name provided in fetch_dataset: Spotify\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:42.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mFetching dataset: Spotify\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:42.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mDownloading dataset from github\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:43.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1mDataset downloaded successfully at ~/stream_topic_data/\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:43.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mDownloading dataset info from github\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:43.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.data_downloader\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mDataset info downloaded successfully at ~/stream_topic_data/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset.fetch_dataset('Spotify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What They Want</td>\n",
       "      <td>165853</td>\n",
       "      <td>1</td>\n",
       "      <td>['Russ']</td>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.404</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>0.48400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.398</td>\n",
       "      <td>139.553</td>\n",
       "      <td>4</td>\n",
       "      <td>yeah ooh yeah they let the rap game yeah yeah ...</td>\n",
       "      <td>75</td>\n",
       "      <td>[yeah, ooh, yeah, they, let, the, rap, game, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shores</td>\n",
       "      <td>281367</td>\n",
       "      <td>0</td>\n",
       "      <td>['Seinabo Sey', 'Vargas &amp; Lagola']</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.491</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.615</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.32200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.275</td>\n",
       "      <td>143.879</td>\n",
       "      <td>4</td>\n",
       "      <td>seinabo sey have always wondered your cause wh...</td>\n",
       "      <td>58</td>\n",
       "      <td>[seinabo, sey, have, always, wondered, your, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Prayer</td>\n",
       "      <td>255360</td>\n",
       "      <td>0</td>\n",
       "      <td>['Anthony Callea']</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.460</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.76800</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.109</td>\n",
       "      <td>138.822</td>\n",
       "      <td>4</td>\n",
       "      <td>youll our eyes and watch where and when dont k...</td>\n",
       "      <td>37</td>\n",
       "      <td>[youll, our, eyes, and, watch, where, and, whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Send Me the Pillow You Dream On</td>\n",
       "      <td>147440</td>\n",
       "      <td>0</td>\n",
       "      <td>['Hank Locklin']</td>\n",
       "      <td>2003-03-03</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.308</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.624</td>\n",
       "      <td>119.755</td>\n",
       "      <td>4</td>\n",
       "      <td>send the pillow that you dream dont you know t...</td>\n",
       "      <td>45</td>\n",
       "      <td>[send, the, pillow, that, you, dream, dont, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's a Rainy Day</td>\n",
       "      <td>255400</td>\n",
       "      <td>0</td>\n",
       "      <td>['Ice Mc']</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.736</td>\n",
       "      <td>2</td>\n",
       "      <td>-11.686</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.00482</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.484</td>\n",
       "      <td>134.955</td>\n",
       "      <td>4</td>\n",
       "      <td>alexia and ice you the came down you were life...</td>\n",
       "      <td>41</td>\n",
       "      <td>[alexia, and, ice, you, the, came, down, you, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  duration_ms  explicit  \\\n",
       "0                   What They Want       165853         1   \n",
       "1                           Shores       281367         0   \n",
       "2                       The Prayer       255360         0   \n",
       "3  Send Me the Pillow You Dream On       147440         0   \n",
       "4                 It's a Rainy Day       255400         0   \n",
       "\n",
       "                              artists release_date  danceability  energy  key  \\\n",
       "0                            ['Russ']   2017-05-05         0.710   0.404    1   \n",
       "1  ['Seinabo Sey', 'Vargas & Lagola']   2019-09-20         0.431   0.491    5   \n",
       "2                  ['Anthony Callea']         2005         0.217   0.460   10   \n",
       "3                    ['Hank Locklin']   2003-03-03         0.595   0.308    3   \n",
       "4                          ['Ice Mc']   2008-03-16         0.619   0.736    2   \n",
       "\n",
       "   loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0   -10.040     0       0.3790       0.48400          0.000000    0.0953   \n",
       "1    -6.615     1       0.0288       0.32200          0.000000    0.0679   \n",
       "2    -5.133     1       0.0302       0.76800          0.000008    0.0847   \n",
       "3   -11.626     1       0.0333       0.84000          0.000004    0.0942   \n",
       "4   -11.686     0       0.0302       0.00482          0.001050    0.3350   \n",
       "\n",
       "   valence    tempo  time_signature  \\\n",
       "0    0.398  139.553               4   \n",
       "1    0.275  143.879               4   \n",
       "2    0.109  138.822               4   \n",
       "3    0.624  119.755               4   \n",
       "4    0.484  134.955               4   \n",
       "\n",
       "                                                text  labels  \\\n",
       "0  yeah ooh yeah they let the rap game yeah yeah ...      75   \n",
       "1  seinabo sey have always wondered your cause wh...      58   \n",
       "2  youll our eyes and watch where and when dont k...      37   \n",
       "3  send the pillow that you dream dont you know t...      45   \n",
       "4  alexia and ice you the came down you were life...      41   \n",
       "\n",
       "                                              tokens  \n",
       "0  [yeah, ooh, yeah, they, let, the, rap, game, y...  \n",
       "1  [seinabo, sey, have, always, wondered, your, c...  \n",
       "2  [youll, our, eyes, and, watch, where, and, whe...  \n",
       "3  [send, the, pillow, that, you, dream, dont, yo...  \n",
       "4  [alexia, and, ice, you, the, came, down, you, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah ooh yeah they let the rap game yeah yeah yeah yeah they let this rap game yeah yeah got chick call her she feel like the like and some and feel like she feel like but she aint the only one got chick call her she she and off now she just got the the her they but they aint the only what they want what they want what they want dollar signs yeah know its what they want what they want what they want what they want yall aint fooling all ooh ooh ooh ooh this now they call they yeah off probably the only one yeah when you you all the like got the and and some probably the only one yeah what they want what they want what they want dollar signs yeah know its what they want what they want what they want what they want yall aint fooling all ooh ooh ooh ooh who ill you who fuck just all the what all the fuck they like the but know what they want aint its and but pop pop the let the boss when boss ill what they want what they want what they want dollar signs yeah know its what they want what they want what they want what they want yall aint fooling all ooh ooh ooh ooh',\n",
       " 'seinabo sey have always wondered your cause when you you can not and ive been you your just see one seinabo sey will you ever tell what really your mind cause the greatest love youll ever find seinabo sey moving life better shores you see shores you see sure moving somebody thats sure sure sure see moving moving have always wondered you your like every word the ive always been and every word but the seinabo sey vargas lagola will you ever tell what really your mind cause the greatest love youll ever find you know seinabo sey vargas lagola seinabo sey moving life better shores you see shores you see sure moving somebody thats sure sure sure see moving cause not seinabo sey vargas lagola seinabo sey and you cant hold heart heart heart heart and you cant hold heart heart heart heart you cant hold heart heart hold heart and you cant hold heart heart heart and you cant hold heart heart you cant you cant you cant you cant hold heart heart heart heart heart moving moving ohohooh ohohooh ohohooh']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 58]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simulating some example data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate 1000 random strings of lengths between 1 and 5, containing letters 'A' to 'Z'\n",
    "random_documents = [''.join(np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'), \n",
    "                                             np.random.randint(1, 6))) for _ in range(1000)]\n",
    "\n",
    "# Generate 1000 random labels from 1 to 4 as strings\n",
    "random_labels = np.random.choice(['1', '2', '3', '4'], 1000)\n",
    "\n",
    "# Create DataFrame\n",
    "my_data = pd.DataFrame({\"Documents\": random_documents, \"Labels\": random_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing documents: 100%|██████████| 1000/1000 [00:03<00:00, 251.82it/s]\n",
      "\u001b[32m2024-08-09 15:32:48.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mcreate_load_save_dataset\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mDataset saved to data/sample_data.parquet\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:48.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mcreate_load_save_dataset\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mDataset info saved to data/sample_data_info.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = TMDataset()\n",
    "dataset.create_load_save_dataset(\n",
    "    data=my_data, \n",
    "    dataset_name=\"sample_data\",\n",
    "    save_dir=\"data/\",\n",
    "    doc_column=\"Documents\",\n",
    "    label_column=\"Labels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 15:32:48.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mFetching dataset: sample_data\u001b[0m\n",
      "\u001b[32m2024-08-09 15:32:48.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m128\u001b[0m - \u001b[1mFetching dataset from local path\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# the new data is saved in the data folder unlike the default datasets which are saved in package directory under preprocessed_data folder.\n",
    "# therefore, you need to provide the path to the data folder to fetch the dataset\n",
    "dataset.fetch_dataset(name=\"sample_data\", dataset_path=\"data/\", source=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PVADD</td>\n",
       "      <td>2</td>\n",
       "      <td>[PVADD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV</td>\n",
       "      <td>4</td>\n",
       "      <td>[TV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXG</td>\n",
       "      <td>4</td>\n",
       "      <td>[EXG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>[Y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGHXO</td>\n",
       "      <td>3</td>\n",
       "      <td>[BGHXO]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text labels   tokens\n",
       "0  PVADD      2  [PVADD]\n",
       "1     TV      4     [TV]\n",
       "2    EXG      4    [EXG]\n",
       "3      Y      4      [Y]\n",
       "4  BGHXO      3  [BGHXO]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topicm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
