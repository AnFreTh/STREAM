{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cf4c6f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnFreTh/STREAM/blob/main/docs/notebooks/arabic_testing.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/AnFreTh/STREAM/blob/main/docs/notebooks/arabic_testing.ipynb)\n",
    "\n",
    "# Arabic Topic Modeling with STREAM\n",
    "\n",
    "This notebook demonstrates STREAM's capabilities for Arabic text topic modeling, including specialized preprocessing and model adaptations for Arabic text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ac3aa6-80b3-494e-916b-e5f2a18f2d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\yahya\\my_projects\\stream_env\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required packages\n",
    "import pyarabic\n",
    "from pyarabic.araby import strip_tashkeel, strip_tatweel\n",
    "from pyarabic.normalize import normalize_hamza, normalize_lamalef\n",
    "import unicodedata\n",
    "\n",
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f5b4f",
   "metadata": {},
   "source": [
    "## Loading Arabic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eef740d-ba70-481f-8fce-ff4c11f5771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     c:\\Users\\yahya\\my_projects\\stream_env\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     c:\\Users\\yahya\\my_projects\\stream_env\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyArabic not available. Installing basic preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-15 17:56:23.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mFetching dataset: Arabic_News\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mProcessing Arabic dataset from c:\\users\\yahya\\my_projects\\stream\\stream_topic\\stream_topic_data\\arabic_datasets\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mTried path (not found): c:\\users\\yahya\\my_projects\\stream\\data\\arabic_datasets\\arabic_news\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mTried path (not found): c:\\users\\yahya\\my_projects\\stream\\stream_topic\\stream_topic_data\\arabic_datasets\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mTried path (not found): data\\arabic_datasets\\arabic_news\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m134\u001b[0m - \u001b[34m\u001b[1mTried path (not found): c:\\Users\\yahya\\my_projects\\STREAM\\docs\\notebooks\\data\\arabic_datasets\\arabic_news\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mFound valid dataset path: C:\\Users\\yahya\\my_projects\\STREAM\\stream_topic\\data\\arabic_datasets\\arabic_news\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mLoading data from: C:\\Users\\yahya\\my_projects\\STREAM\\stream_topic\\data\\arabic_datasets\\arabic_news\\Arabiya\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:23.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Culture\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Finance\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Medical\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Politics\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Sports\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mProcessing topic: Tech\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m176\u001b[0m - \u001b[1mSuccessfully processed 11990 files with 0 errors\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:26.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mFound 6 unique topics\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:27.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36m_load_arabic_dataset\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mCached preprocessed dataset to c:\\users\\yahya\\my_projects\\stream\\cache\\preprocessed_datasets\\arabic_news.parquet\u001b[0m\n",
      "\u001b[32m2024-12-15 17:56:27.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mSuccessfully loaded Arabic dataset 'Arabic_News' with 11990 documents\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "Number of documents: 11990\n",
      "Available topics: ['Culture' 'Finance' 'Medical' 'Politics' 'Sports' 'Tech']\n"
     ]
    }
   ],
   "source": [
    "# First import TMDataset\n",
    "from stream_topic.utils.dataset import TMDataset\n",
    "from stream_topic.models import KmeansTM\n",
    "from stream_topic.preprocessor._preprocessor import TextPreprocessor\n",
    "from stream_topic.preprocessor.arabic_preprocessing import ArabicPreprocessor\n",
    "from stream_topic.models.ArabicKmeansTM import ArabicKmeansTM\n",
    "\n",
    "# Initialize and load dataset\n",
    "dataset = TMDataset()\n",
    "dataset.fetch_dataset(\"Arabic_News\")\n",
    "\n",
    "# Print basic information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"Number of documents: {len(dataset.dataframe)}\")\n",
    "print(f\"Available topics: {dataset.dataframe['labels'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a61939",
   "metadata": {},
   "source": [
    "## Preprocessing Arabic Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b6e22b-a11e-4ff4-bdfc-44aec87c99a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11990 documents to preprocess\n",
      "\n",
      "Sample of first 3 documents:\n",
      "Processing text: غيب الموت مساء السبت، الفنان المصري محمود الدسوقي،...\n",
      "Processing text: فاز الفيلم الإيراني \"الصورة الأخيرة لذكرى\" بالجائز...\n",
      "Processing text: عبرت الفنانة الكويتية غدير السبتي عن سعادتها الغام...\n",
      "...(remaining documents omitted)...\n",
      "\n",
      "Preprocessing in progress...\n",
      "Preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the language and preprocess data\n",
    "dataset.language = \"ar\"\n",
    "dataset.preprocess()\n",
    "\n",
    "# Print sample results\n",
    "# print(\"Sample of first 5 documents being preprocessed:\")\n",
    "# for text in dataset.texts[:5]:\n",
    "#     print(f\"Processing text: {text[:100]}...\")\n",
    "# print(\"\\nUnique labels:\", dataset.dataframe['labels'].unique())\n",
    "# print(\"\\nNumber of documents per label:\")\n",
    "# print(dataset.dataframe['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a283cb-3c3b-47ce-848e-287de914ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of preprocessed text:\n",
      "غيب الموت السبت الفنان المصري محمود الدسوقي زوج عزة مجاهد ابنة الفنانة المصرية فيفي عبده إثر إصابته بأزمة قلبية حادة وشيعت جنازة الفنان الراحل مسجد مصطفى محمود بالمهندسين عقب صلاة المغرب ودفن مقابر الأسرة يقام العزاء بمسجد الحادمية الشاذلية ونعت الفنانة فيفي عبده زوج ابنتها صفحتها انستغرام وكتبت لله وإنا إليه راجعون توفي رجل الأعمال والفنان محمود الدسوقي زوج ابنتي عزة مجاهد ووالد ابنتهما شهد الدسوقي فيفي عبده وابنتها ابنه فيفي عبده وزوجها يبلغ الدسوقي العمر عاما وعمل عدد الأعمال الفنية وظهر ممثلا زوجته عزة وحماته الفنانة فيفي عبده العرض المسرحي حارة العوالم وقال التمثيل حماته يعطي طاقة كبيرة المسرح وإنها أعطته ثقة كبيرة تجسيد دوره ظهر فيفي عبده أغنيتها المصورة حرة بحبش ضرة وجسد شخصية زوجها\n",
      "\n",
      "Unique labels: ['Culture' 'Finance' 'Medical' 'Politics' 'Sports' 'Tech']\n",
      "\n",
      "Number of documents per label:\n",
      "labels\n",
      "Culture     2000\n",
      "Medical     2000\n",
      "Sports      2000\n",
      "Tech        2000\n",
      "Finance     1999\n",
      "Politics    1991\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# After loading dataset but before training\n",
    "print(\"Sample of preprocessed text:\")\n",
    "print(dataset.dataframe['text'].iloc[0])\n",
    "print(\"\\nUnique labels:\", dataset.dataframe['labels'].unique())\n",
    "print(\"\\nNumber of documents per label:\")\n",
    "print(dataset.dataframe['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f53d3d",
   "metadata": {},
   "source": [
    "## Training the Topic Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70a1be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-15 17:57:06.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.ArabicKmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mTraining ArabicKmeansTM\u001b[0m\n",
      "\u001b[32m2024-12-15 17:57:06.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.ArabicKmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mUsing TF-IDF approach\u001b[0m\n",
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:394: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['أفعل', 'أفعله', 'انفك', 'برح', 'سيما'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:394: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['أفعل', 'أفعله', 'انفك', 'برح', 'سيما'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11990/11990 [25:28<00:00,  7.85it/s] \n",
      "\u001b[32m2024-12-15 18:23:11.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-12-15 18:23:32.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.ArabicKmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Topics:\n",
      "\n",
      "Topic 0:\n",
      "الأهلي, الهلال, السعودي, مباراة, النصر, الفريق, النادي, المباراة, الموسم, الاتحاد\n",
      "\n",
      "Topic 1:\n",
      "سوريا, النظام, حلب, المعارضة, السوري, السورية, قوات, الأسد, المرصد, داعش\n",
      "\n",
      "Topic 2:\n",
      "النفط, برميل, للبرميل, أوبك, الخام, يوميا, أسعار, برنت, الإنتاج, مخزونات\n",
      "\n",
      "Topic 3:\n",
      "الفنانة, الفنان, المسلسل, مسلسل, محمد, الدراما, المخرج, الأغنية, أحمد, الفنانين\n",
      "\n",
      "Topic 4:\n",
      "مباراة, الدوري, مدريد, القدم, الفريق, الموسم, برشلونة, المدرب, لكرة, المباراة\n",
      "\n",
      "Topic 5:\n",
      "البنك, الدولار, المركزي, البنوك, أسعار, مليار, الفائدة, بنك, سعر, العملة\n",
      "\n",
      "Topic 6:\n",
      "الجسم, تناول, الدم, النوم, الأطعمة, الدهون, الوزن, القلب, الغذائية, الإصابة\n",
      "\n",
      "Topic 7:\n",
      "التطبيق, تطبيق, أندرويد, المستخدم, التطبيقات, متجر, لمستخدمي, تطبيقات, الصور, للمستخدمين\n",
      "\n",
      "Topic 8:\n",
      "شركة, دبي, مليار, المملكة, الشركة, المالية, الشركات, السوق, الإمارات, مجلس\n",
      "\n",
      "Topic 9:\n",
      "آبل, آيفون, شركة, هواتف, هاتف, الشركة, آيباد, الهاتف, الذكية, سامسونغ\n",
      "\n",
      "Topic 10:\n",
      "الرئيس, الأميركية, إيران, وزير, الاتحاد, مجلس, الحكومة, الأمن, محمد, الدول\n",
      "\n",
      "Topic 11:\n",
      "الفيروس, الصحة, زيكا, فيروس, إصابة, المرض, بفيروس, بالفيروس, إيبولا, منظمة\n",
      "\n",
      "Topic 12:\n",
      "الدراسة, الباحثون, الإصابة, دراسة, القلب, الدم, الأطفال, السرطان, خطر, التدخين\n",
      "\n",
      "Topic 13:\n",
      "الشوط, الدقيقة, الحارس, المباراة, تمريرة, التعادل, الكرة, مضيفه, ضيفه, كرة\n",
      "\n",
      "Topic 14:\n",
      "الحوثي, داعش, القوات, التحالف, ميليشيات, الميليشيات, الموصل, تعز, قوات, الحوثيين\n",
      "\n",
      "Topic 15:\n",
      "الهاتف, سامسونغ, غالاكسي, هاتف, شركة, الشركة, غيغابايت, بدقة, جيجابايت, الجهاز\n",
      "\n",
      "Topic 16:\n",
      "مليار, الربع, بنسبة, بقيمة, سهم, الأسهم, مقارنة, الشركة, إجمالي, تعاملات\n",
      "\n",
      "Topic 17:\n",
      "فيسبوك, المستخدمين, تويتر, الميزة, المستخدم, الاجتماعي, مستخدمي, الشركة, مستخدم, ميزة\n",
      "\n",
      "Topic 18:\n",
      "الفيلم, فيلم, المهرجان, المخرج, السينما, الأفلام, السينمائي, مهرجان, للمخرج, أفلام\n",
      "\n",
      "Topic 19:\n",
      "غوغل, شركة, الشركة, مايكروسوفت, ويندوز, المستخدم, الذكية, الإنترنت, الهواتف, جوجل\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "model = ArabicKmeansTM(num_topics=20)\n",
    "model.fit(dataset)\n",
    "\n",
    "# Get and display topics\n",
    "topics = model.get_topics()\n",
    "print(\"\\nExtracted Topics:\")\n",
    "for idx, topic in enumerate(topics):\n",
    "    print(f\"\\nTopic {idx}:\")\n",
    "    print(\", \".join(topic[:10]))  # Print top 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776ec41-29c4-4a87-a43b-42f058c4ec83",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c848bc-9098-4ae3-86fe-1dc1b64e0b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ISIM Score: 0.7935564905405045\n",
      "\n",
      "Per-topic scores:\n",
      "الأهلي, الهلال, السعودي, مباراة, النصر...: 0.7896\n",
      "سوريا, النظام, حلب, المعارضة, السوري...: 0.7890\n",
      "النفط, برميل, للبرميل, أوبك, الخام...: 0.8372\n",
      "الفنانة, الفنان, المسلسل, مسلسل, محمد...: 0.8264\n",
      "مباراة, الدوري, مدريد, القدم, الفريق...: 0.8076\n",
      "البنك, الدولار, المركزي, البنوك, أسعار...: 0.8541\n",
      "الجسم, تناول, الدم, النوم, الأطعمة...: 0.6438\n",
      "التطبيق, تطبيق, أندرويد, المستخدم, التطبيقات...: 0.8408\n",
      "شركة, دبي, مليار, المملكة, الشركة...: 0.8017\n",
      "آبل, آيفون, شركة, هواتف, هاتف...: 0.7268\n",
      "الرئيس, الأميركية, إيران, وزير, الاتحاد...: 0.8411\n",
      "الفيروس, الصحة, زيكا, فيروس, إصابة...: 0.7369\n",
      "الدراسة, الباحثون, الإصابة, دراسة, القلب...: 0.8545\n",
      "الشوط, الدقيقة, الحارس, المباراة, تمريرة...: 0.7950\n",
      "الحوثي, داعش, القوات, التحالف, ميليشيات...: 0.8284\n",
      "الهاتف, سامسونغ, غالاكسي, هاتف, شركة...: 0.7491\n",
      "مليار, الربع, بنسبة, بقيمة, سهم...: 0.7971\n",
      "فيسبوك, المستخدمين, تويتر, الميزة, المستخدم...: 0.7692\n",
      "الفيلم, فيلم, المهرجان, المخرج, السينما...: 0.8475\n",
      "غوغل, شركة, الشركة, مايكروسوفت, ويندوز...: 0.7573\n"
     ]
    }
   ],
   "source": [
    "from stream_topic.metrics import ISIM, INT, ISH, Expressivity, NPMI\n",
    "\n",
    "# Calculate ISIM score\n",
    "metric = ISIM()\n",
    "isim_score = metric.score(topics)\n",
    "print(f\"\\nISIM Score: {isim_score}\")\n",
    "\n",
    "# Calculate per-topic scores\n",
    "topic_scores = metric.score_per_topic(topics)\n",
    "print(\"\\nPer-topic scores:\")\n",
    "for topic, score in topic_scores.items():\n",
    "    print(f\"{topic[:50]}...: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada3616",
   "metadata": {},
   "source": [
    "## Visualizing Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a10e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yahya\\my_projects\\stream_env\\lib\\site-packages\\dash\\dash.py:2282: DeprecationWarning:\n",
      "\n",
      "Dash.run_server is deprecated and will be removed in Dash 3.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x236cb0c0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stream_topic.visuals import visualize_topic_model\n",
    "\n",
    "visualize_topic_model(\n",
    "    model, \n",
    "    reduce_first=True, \n",
    "    port=8051,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b9cd1",
   "metadata": {},
   "source": [
    "## Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc998e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Perform hyperparameter optimization\n",
    "# model.optimize_and_fit(\n",
    "#     dataset,\n",
    "#     min_topics=2,\n",
    "#     max_topics=20,\n",
    "#     criterion=\"aic\",\n",
    "#     n_trials=20,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
