{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnFreTh/STREAM/blob/main/docs/notebooks/examples.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/AnFreTh/STREAM/blob/main/docs/notebooks/examples.ipynb)\n",
    "\n",
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line if running in Colab\n",
    "# package neeeds to be installed for the notebook to run\n",
    "\n",
    "# ! pip install -U stream_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/topicm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stream_topic.models import KmeansTM\n",
    "from stream_topic.utils import TMDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize model parameters via bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-08 22:58:17.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mFetching dataset: BBC_News\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:17.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m715\u001b[0m - \u001b[1mDownloading dataset from github\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:17.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m717\u001b[0m - \u001b[1mDataset downloaded successfully at ~/stream_topic_data/ folder\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:18.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m744\u001b[0m - \u001b[1mDownloading dataset info from github\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:18.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mload_custom_dataset_from_url\u001b[0m:\u001b[36m746\u001b[0m - \u001b[1mDataset info downloaded successfully at ~/stream_topic_data/ folder\u001b[0m\n",
      "Preprocessing documents: 100%|██████████| 2225/2225 [00:11<00:00, 199.14it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TMDataset()\n",
    "dataset.fetch_dataset(\"BBC_News\")\n",
    "dataset.preprocess(model_type=\"KmeansTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 22:58:29,700] A new study created in memory with name: no-name-75ffbc6e-83ae-457d-a3d2-7aeba0e416e6\n",
      "\u001b[32m2024-08-08 22:58:29.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:29.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:29.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "\u001b[32m2024-08-08 22:58:34.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:35.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:35,153] Trial 0 finished with value: -3352.7655766404446 and parameters: {'n_topics': 3, 'n_neighbors': 39, 'n_components': 32, 'metric': 'euclidean', 'init': 'k-means++', 'n_init': 23, 'max_iter': 139}. Best is trial 0 with value: -3352.7655766404446.\n",
      "\u001b[32m2024-08-08 22:58:35.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:35.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:35.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:37.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:37.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:37,867] Trial 1 finished with value: -2872.343492004661 and parameters: {'n_topics': 12, 'n_neighbors': 24, 'n_components': 11, 'metric': 'euclidean', 'init': 'random', 'n_init': 16, 'max_iter': 685}. Best is trial 0 with value: -3352.7655766404446.\n",
      "\u001b[32m2024-08-08 22:58:37.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:37.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:37.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:41.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:42.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:42,434] Trial 2 finished with value: -3214.600874935477 and parameters: {'n_topics': 7, 'n_neighbors': 43, 'n_components': 38, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 30, 'max_iter': 719}. Best is trial 0 with value: -3352.7655766404446.\n",
      "\u001b[32m2024-08-08 22:58:42.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:42.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:42.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:45.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:45.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:45,998] Trial 3 finished with value: -2895.9096335096447 and parameters: {'n_topics': 9, 'n_neighbors': 30, 'n_components': 44, 'metric': 'cosine', 'init': 'random', 'n_init': 14, 'max_iter': 630}. Best is trial 0 with value: -3352.7655766404446.\n",
      "\u001b[32m2024-08-08 22:58:46.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:46.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:46.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:48.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:49.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:49,196] Trial 4 finished with value: -3409.0571393465452 and parameters: {'n_topics': 8, 'n_neighbors': 44, 'n_components': 39, 'metric': 'euclidean', 'init': 'random', 'n_init': 17, 'max_iter': 546}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:58:49.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:49.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:49.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:52.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:53.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:53,337] Trial 5 finished with value: -3167.135520040184 and parameters: {'n_topics': 16, 'n_neighbors': 43, 'n_components': 45, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 10, 'max_iter': 237}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:58:53.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:53.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:53.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:56.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:58.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:58:58,367] Trial 6 finished with value: -3142.9181565529775 and parameters: {'n_topics': 8, 'n_neighbors': 44, 'n_components': 35, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 14, 'max_iter': 401}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:58:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:58:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:01.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:02.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:59:02,134] Trial 7 finished with value: -2716.391105658633 and parameters: {'n_topics': 4, 'n_neighbors': 20, 'n_components': 43, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 11, 'max_iter': 467}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:59:02.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:02.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:02.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:05.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:06.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:59:06,252] Trial 8 finished with value: -2966.0930975743463 and parameters: {'n_topics': 19, 'n_neighbors': 29, 'n_components': 26, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 27, 'max_iter': 460}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:59:06.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:06.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:06.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:09.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:10.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-08 22:59:10,746] Trial 9 finished with value: -2983.739081221937 and parameters: {'n_topics': 6, 'n_neighbors': 29, 'n_components': 45, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 25, 'max_iter': 875}. Best is trial 4 with value: -3409.0571393465452.\n",
      "\u001b[32m2024-08-08 22:59:10.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36moptimize_hyperparameters\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mOptimal parameters: {'n_neighbors': 44, 'n_components': 39, 'metric': 'euclidean', 'init': 'random', 'n_init': 17, 'max_iter': 546} with 8 topics based on AIC.\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:10.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:10.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:10.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:14.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-08 22:59:14.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = KmeansTM()\n",
    "output = model.optimize_and_fit(dataset, n_trials=10, max_topics=20, min_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "topics = model.get_topics()\n",
    "print(len(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stream_topic.metrics import NPMI, ISIM\n",
    "\n",
    "metric = NPMI(dataset)\n",
    "metric.score(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1823512502014637"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isim_metric = ISIM()\n",
    "isim_metric.score(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
