{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnFreTh/STREAM/blob/develop/docs/notebooks/examples.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/AnFreTh/STREAM/blob/develop/docs/notebooks/examples.ipynb)\n",
    "\n",
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stream_topic.models import KmeansTM\n",
    "from stream_topic.utils import TMDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize model parameters via bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 10:42:28.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFetching dataset: BBC_News\u001b[0m\n",
      "\u001b[32m2024-08-07 10:42:28.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.utils.dataset\u001b[0m:\u001b[36mfetch_dataset\u001b[0m:\u001b[36m168\u001b[0m - \u001b[1mDataset loaded successfully from c:\\users\\anton\\desktop\\projects\\stream\\stream_topic\\preprocessed_datasets\\BBC_News\u001b[0m\n",
      "Preprocessing documents: 100%|██████████| 2225/2225 [00:29<00:00, 75.02it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = TMDataset()\n",
    "dataset.fetch_dataset(\"BBC_News\")\n",
    "dataset.preprocess(model_type=\"KmeansTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 10:42:58,290] A new study created in memory with name: no-name-c7f401f5-97c5-4cdb-857b-6f50683772d8\n",
      "\u001b[32m2024-08-07 10:42:58.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:42:58.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:42:58.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:14.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:15.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:43:15,111] Trial 0 finished with value: -2908.3807001524565 and parameters: {'n_topics': 5, 'n_neighbors': 25, 'n_components': 45, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 12, 'max_iter': 521}. Best is trial 0 with value: -2908.3807001524565.\n",
      "\u001b[32m2024-08-07 10:43:15.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:15.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:15.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:24.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:25.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:43:25,069] Trial 1 finished with value: -3369.708145534729 and parameters: {'n_topics': 8, 'n_neighbors': 44, 'n_components': 15, 'metric': 'euclidean', 'init': 'random', 'n_init': 18, 'max_iter': 719}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:43:25.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:25.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:25.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:31.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:32.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:43:32,734] Trial 2 finished with value: -2352.3949029947194 and parameters: {'n_topics': 13, 'n_neighbors': 10, 'n_components': 11, 'metric': 'euclidean', 'init': 'k-means++', 'n_init': 11, 'max_iter': 747}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:43:32.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:32.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:32.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:43.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:44.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:43:44,275] Trial 3 finished with value: -3050.2628007635785 and parameters: {'n_topics': 8, 'n_neighbors': 30, 'n_components': 31, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 30, 'max_iter': 399}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:43:44.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:44.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:44.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:53.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:53.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:43:53,936] Trial 4 finished with value: -3077.4218904505196 and parameters: {'n_topics': 4, 'n_neighbors': 31, 'n_components': 32, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 21, 'max_iter': 228}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:43:53.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:53.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:43:53.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:04.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:05.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:44:05,325] Trial 5 finished with value: -3316.4025635845546 and parameters: {'n_topics': 8, 'n_neighbors': 47, 'n_components': 39, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 22, 'max_iter': 664}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:44:05.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:05.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:05.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:14.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:15.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:44:15,314] Trial 6 finished with value: -2375.983772695624 and parameters: {'n_topics': 3, 'n_neighbors': 14, 'n_components': 35, 'metric': 'euclidean', 'init': 'random', 'n_init': 20, 'max_iter': 889}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:44:15.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:15.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:15.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:23.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:24.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:44:24,310] Trial 7 finished with value: -2731.111202206049 and parameters: {'n_topics': 15, 'n_neighbors': 19, 'n_components': 10, 'metric': 'cosine', 'init': 'k-means++', 'n_init': 14, 'max_iter': 492}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:44:24.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:24.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:24.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:31.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:32.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:44:32,529] Trial 8 finished with value: -1749.2967260199991 and parameters: {'n_topics': 13, 'n_neighbors': 10, 'n_components': 18, 'metric': 'cosine', 'init': 'random', 'n_init': 11, 'max_iter': 412}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:44:32.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:32.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:32.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:41.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:42.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n",
      "[I 2024-08-07 10:44:42,270] Trial 9 finished with value: -2846.653885685785 and parameters: {'n_topics': 15, 'n_neighbors': 29, 'n_components': 29, 'metric': 'cosine', 'init': 'random', 'n_init': 21, 'max_iter': 428}. Best is trial 1 with value: -3369.708145534729.\n",
      "\u001b[32m2024-08-07 10:44:42.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36moptimize_hyperparameters\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mOptimal parameters: {'n_neighbors': 44, 'n_components': 15, 'metric': 'euclidean', 'init': 'random', 'n_init': 18, 'max_iter': 719} with 8 topics based on AIC.\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:42.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:42.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mprepare_embeddings\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1m--- Loading precomputed paraphrase-MiniLM-L3-v2 embeddings ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:42.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.abstract_helper_models.base\u001b[0m:\u001b[36mdim_reduction\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:51.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-08-07 10:44:51.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream_topic.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = KmeansTM()\n",
    "output = model.optimize_and_fit(dataset, n_trials=10, max_topics=20, min_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "topics = model.get_topics()\n",
    "print(len(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stream_topic.metrics import NPMI, ISIM\n",
    "\n",
    "metric = NPMI(dataset)\n",
    "metric.score(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20205374993383884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isim_metric = ISIM()\n",
    "isim_metric.score(topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stream_topic_venv)",
   "language": "python",
   "name": "stream_topic_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
