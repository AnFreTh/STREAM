{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since STREAM is using the preprocessing from the octis core package, you must download some spacy specific utils.\n",
    "\n",
    "python -m spacy download en_core_web_sm before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\anaconda3\\envs\\STREAM_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\anton\\anaconda3\\envs\\STREAM_venv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "c:\\Users\\anton\\anaconda3\\envs\\STREAM_venv\\lib\\site-packages\\dash\\_jupyter.py:31: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  _dash_comm = Comm(target_name=\"dash\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from stream.utils import TMDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simulating some example data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "# Generate 1000 random strings of lengths between 1 and 5, containing letters 'A' to 'Z'\n",
    "random_documents = [''.join(np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'), \n",
    "                                             np.random.randint(1, 6))) for _ in range(1000)]\n",
    "\n",
    "# Generate 1000 random labels from 1 to 4 as strings\n",
    "random_labels = np.random.choice(['1', '2', '3', '4'], 1000)\n",
    "\n",
    "# Create DataFrame\n",
    "my_data = pd.DataFrame({\"Documents\": random_documents, \"Labels\": random_labels})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass the dataframe to the create_load_save_dataset function and specify the used columns. use label_column=None if no labels are available.\n",
    "The dataset is preprocessed and saved and directly returned. If you want to use your dataset later, you can simply run dataset.fetch_dataset(your_dataset_path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing documents: 100%|██████████| 1000/1000 [00:13<00:00, 75.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TMDataset()\n",
    "dataset = dataset.create_load_save_dataset(\n",
    "    data=my_data, \n",
    "    dataset_name=\"my_dataset_name\",\n",
    "    save_dir=\"my_dataset_save_directory\",\n",
    "    doc_column=\"Documents\",\n",
    "    label_column=\"Labels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To fecth the dataset, simply run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TMDataset()\n",
    "dataset.fetch_dataset(name=\"my_dataset_name\", dataset_path=\"my_dataset_save_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-23 13:19:19.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m262\u001b[0m - \u001b[1m--- Training KmeansTM topic model ---\u001b[0m\n",
      "\u001b[32m2024-06-23 13:19:19.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream.models.KmeansTM\u001b[0m:\u001b[36m_prepare_embeddings\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1m--- Creating paraphrase-MiniLM-L3-v2 document embeddings ---\u001b[0m\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 155.09it/s]\n",
      "\u001b[32m2024-06-23 13:19:25.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream.models.KmeansTM\u001b[0m:\u001b[36m_dim_reduction\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1m--- Reducing dimensions ---\u001b[0m\n",
      "\u001b[32m2024-06-23 13:19:35.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream.models.KmeansTM\u001b[0m:\u001b[36m_clustering\u001b[0m:\u001b[36m214\u001b[0m - \u001b[1m--- Creating document cluster ---\u001b[0m\n",
      "\u001b[32m2024-06-23 13:19:35.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstream.models.KmeansTM\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m295\u001b[0m - \u001b[1m--- Training completed successfully. ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vb', 'ld', 'rd', 'ncb', 'hmaul', 'vjebr', 'vhk', 'vg', 'vfhy', 'vf'], ['ps', 'lot', 'mu', 'nose', 'psce', 'warm', 'fl', 'byvet', 'jp', 'id'], ['eq', 'et', 'eqzdh', 'eqtoi', 'ev', 'ejiu', 'eyvh', 'ezako', 'egum', 'egarx'], ['hv', 'hws', 'hxohw', 'hu', 'htnsy', 'htafl', 'hxr', 'hyyp', 'hb', 'hbbh'], ['pe', 'ki', 'pekr', 'krlri', 'kkacb', 'kmgd', 'kmr', 'kn', 'knsb', 'knvb'], ['jd', 'gj', 'ullfq', 'pfjw', 'wrgh', 'ws', 'ortdj', 'jvh', 'wwm', 'jjma'], ['zd', 'zzg', 'zmism', 'zya', 'ixtp', 'sqzh', 'wuchn', 'zanmg', 'zarh', 'zfnv'], ['ov', 'oa', 'oinjo', 'ocro', 'ooson', 'oou', 'oat', 'oqub', 'oygny', 'oy'], ['tkg', 'tlg', 'oflt', 'tgo', 'tm', 'jp', 'jon', 'jo', 'jmmt', 'jmafw'], ['xsk', 'xooqd', 'xqfca', 'xqhlk', 'xo', 'xtz', 'xn', 'xyy', 'xly', 'xzos'], ['si', 'ysd', 'ybf', 'yrtt', 'ys', 'yp', 'yn', 'yv', 'yydsp', 'yynx'], ['dy', 'dp', 'dsrbs', 'dmeb', 'dmeui', 'dmgpe', 'dgcf', 'dfmsa', 'ds', 'dn'], ['sb', 'en', 'ab', 'rf', 'bveff', 'bue', 'bma', 'ukkur', 'bh', 'bee'], ['qci', 'qcp', 'qcl', 'qcw', 'qcfuc', 'qcbwn', 'qc', 'qco', 'hrf', 'jqgvd'], ['vz', 'vmzk', 'gg', 'woz', 'kwza', 'ouvd', 'oszm', 'osza', 'wvvz', 'osao'], ['lf', 'lml', 'lrjaw', 'lxg', 'lxc', 'lx', 'lwaen', 'lvmpx', 'yfcml', 'lqd'], ['ib', 'og', 'uc', 'da', 'ua', 'dh', 'ih', 'th', 'ng', 'tarcs'], ['fb', 'mrqp', 'wqp', 'fsyq', 'whmqq', 'ecq', 'qifpf', 'fvo', 'fvq', 'wnxzq'], ['rk', 'hyzym', 'rgpcv', 'rhb', 'rhc', 'rhk', 'ftxyt', 'rkh', 'rkm', 'rpq'], ['mw', 'qld', 'qmfu', 'qksxu', 'km', 'qlbz', 'qysf', 'qlv', 'qm', 'qni']]\n"
     ]
    }
   ],
   "source": [
    "from stream.models import KmeansTM\n",
    "# -> specify a existing folder path where to save the embeddings (or where to load the pre embedded dataset)\n",
    "model = KmeansTM(embeddings_folder_path=\"../my_embedding_folder\")  \n",
    "# -> set the following arguments for num_topic optimization: KmeansTM(optim = True, optim_range = [5, 25])\n",
    "model.fit(dataset)  \n",
    "topics = model.get_topics()\n",
    "print(topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stream_venv",
   "language": "python",
   "name": "stream_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
