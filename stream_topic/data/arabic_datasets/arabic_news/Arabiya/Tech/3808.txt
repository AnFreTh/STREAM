في محاكاة كمبيوتر بسيطة، تقوم مجموعة من السيارات ذاتية القيادة بأداء مناورة مجنونة على طريق سريع افتراضي رباعي الحارات. تسعى نصف السيارات إلى التحرك من أقصى الحارات اليمنى، بينما يحاول النصف الآخر أن ينفذ من الحارات اليسرى. تبدو المناورة بالغة الصعوبة بدرجة ربما تسبب إرباكا للمركبات ذاتية التحكم، لكنها تستطيع أن تسيطر على الوضع بدقة وإحكام. بحسب ما نشره موقع "Technology Review"، تم عرض تلك المحاكاة للقيادة والمناورة على طريق سريع في أكبر مؤتمر للذكاء الصناعي، الذي عقد في برشلونة في ديسمبر الماضي. و المدهش في هذا الأمر هو أن البرنامج الذي يحكم سلوك السيارات ذاتية التحكم، لم تتم برمجته بالمعنى التقليدي على الإطلاق. لقد تعلمت المركبات ذاتية التحكم كيفية الاندماج بمهارة وأمان، وببساطة عن طريق الممارسة. وأثناء التدريب، أجرى برنامج التحكم تلك المناورة مرارا وتكرارا، مع تغيير التعليمات قليلا في كل محاولة. وفي معظم الوقت، تم بنجاح حدوث الاندماج للطريق السريع ببطء شديد، بينما تتداخل السيارات مع بعضها بعضا. ولكن كلما مضى الاندماج بسلاسة، فإن النظام يتعلم كيفية تفضيل السلوك الذي أدى إلى بلوغ الإندماج.




تعزيز التعلم والتوسع في التطبيق إن هذا النهج، والمعروف باسم تعزيز التعلم، يبين أيضا وإلى حد كبير كيف تسنى لـAlphaGo "ألفاغو"، برنامج الكمبيوتر الذي وضعته شركة "DeepMind" التابعة لمجموعة شركات Alphabet، والذي بلغ درجة عالية من إجادة لعبة Go المعقدة، لدرجة أنه هزم أحد أفضل اللاعبين على مستوى العالم ، في مباراة رفيعة المستوى في العام الماضي. والآن فإن تعزيزالتعلم يعد بإمكانية يضخ مزيدا من الذكاء في مجال أكبر بكثير من مجال الألعاب قريبا. فبالإضافة إلى تحسين السيارات ذاتية القيادة، يمكن للتكنولوجيا أن تنتج روبوتا يمكنه أن يفهم الأشياء التي لم يسبق له رؤيتها من قبل، وأنه يمكنه معرفة التكوين الأمثل للمعدات في أي مركز للبيانات.




محاكاة القطط والفأر في المتاهة إن تعزيز التعلم يحاكي مبدأ بسيطا جدا من الطبيعة. وقد وثق الطبيب النفساني إدوارد ثورندايك ذلك منذ أكثر من 100 عام، عندما وضع قططا داخل صناديق لا يمكنها الهروب منها إلا عن طريق الضغط على رافعة. وبعد قدر كبير من التحرك بسرعة والمواء، فإن الحيوانات تخطو في نهاية المطاف فوق الرافعة بطريق الصدفة. وبعد أن تعلمت القطط الربط بين هذا السلوك والنتيجة المرجوة، فإنها تنجح في النجاة في نهاية المطاف وتهرب بمنتهى السرعة. ويعتقد بعض أوائل الباحثين القدامى في مجال الذكاء الصناعي أن هذه العملية يمكن أن تكون مستنسخة بشكل مفيد في الآلات. ففي عام 1951، قام مارفين مينسكي، أحد طلاب جامعة هارفارد، والذي أصبح فيما بعد واحدا من الآباء المؤسسين للذكاء الصناعي، بإحراز نجاح غير مسبوق، كأستاذ في معهد ماساتشوستس للتكنولوجيا، في بناء آلة تستخدم شكلا بسيطا من تعزيز التعلم بمحاكاة تعلم فأر للتنقل في متاهة مينسكي عبر كمبيوتر تعزيز التناظر الوظيفي العشوائي، المعروف اختصارا باسم SNARC، والمكون من عشرات الأنابيب والمحركات والقوابض التي تحاكي سلوك 40 خلية عصبية ونقاط اشتباك عصبي. وكما شق فأر افتراضي طريقه للخروج من المتاهة، فإن قوة بعض الاتصالات المتشابكة سوف تتزايد، مما يعزز السلوك الكامن. لعب الطاولة بمهارة وإنجاز في لعبة Go وكانت هناك بعض النجاحات على مدى العقود القليلة اللاحقة.وفي العام 1992، قدم جيرالد تيسورو، الباحث في IBM، برنامجا يستخدم هذه التقنية للعب الطاولة. وأصبح ماهرا بما فيه الكفاية لمنافسة أفضل اللاعبين من البشر، ويعتبر هذا إنجازا بارزا في مجال الذكاء الصناعي. إلا أن تعزيز التعلم أثبت أنه من الصعب توسيع نطاقه ليشمل مشاكل أكثر تعقيدا. يقول ديفيد سيلفر، الباحث في DeepMind في المملكة المتحدة، والمؤيد البارز لتدعيم التعلم اليوم: "كان الناس يعتقدون أنها فكرة جيدة، والتي لم تنجح حقا". إلا أن هذا الرأي تغير بشكل كبير في مارس 2016. وذلك عندما نجح برنامج AlphaGo، في التدريب باستخدام تعزيز التعلم، في الفوز الساحق على الكوري الجنوبي لي سيدول، أفضل لاعبي Go على مستوى العالم.




وكان هذا الانجاز مذهلا، لأنه من المستحيل تقريبا بناء برنامج Go جيد بالبرمجة التقليدية، ليس فقط لأنها لعبة معقدة للغاية، ولكن لأن لاعبي Go يكافحون لتوضيح لماذا تكون تحركات معينة جيدة أو سيئة، وبالتالي فإنه من الصعب تدوين شفرة تتضمن مبادئ اللعبة. وقد أسفر نهج "تعزيز التعلم" عن التوصل لمستويات تقدم فاقت توقعات الخبراء والباحثين، حيث أن معظم الباحثين في مجال الذكاء الصناعي لم توقعوا أن يتمكن الكمبيوتر من ممارسة الألعاب بمهارة وتفوق اللاعبين من البشر قبل 10 أعوام على أقل تقدير.